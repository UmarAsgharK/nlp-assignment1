{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 Code mostly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist, bigrams, trigrams\n",
    "\n",
    "# nltk.download('punkt')\n",
    "\n",
    "reviews = []\n",
    "with open(\"IMDB Dataset.csv\", encoding='utf-8') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        if row:\n",
    "            reviews.append(row[0])\n",
    "\n",
    "reviews_text = ' '.join(reviews)\n",
    "tokens = word_tokenize(reviews_text)\n",
    "lowercase_tokens = [token.lower() for token in tokens]\n",
    "cleaned_list = [word for word in lowercase_tokens if word.isalpha()]\n",
    "removed_br = [word for word in cleaned_list if word != \"br\"]  # Remove 'br' tokens, which are breakline characters\n",
    "\n",
    "unigram_freqdist = FreqDist(removed_br)\n",
    "\n",
    "bigrams_list = list(bigrams(removed_br))\n",
    "bigram_freqdist = FreqDist(bigrams_list)\n",
    "\n",
    "trigrams_list = list(trigrams(removed_br))\n",
    "trigram_freqdist = FreqDist(trigrams_list)\n",
    "\n",
    "def predict_unigram():\n",
    "    return unigram_freqdist.max()\n",
    "\n",
    "def predict_bigram(prev_word):\n",
    "    candidates = [bigram for bigram in bigram_freqdist if bigram[0] == prev_word]\n",
    "    \n",
    "    if candidates:\n",
    "        return max(candidates, key=lambda x: bigram_freqdist[x])[1]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def predict_trigram(prev_two_words):\n",
    "    candidates = [trigram for trigram in trigram_freqdist if (trigram[0], trigram[1]) == prev_two_words]\n",
    "    \n",
    "    if candidates:\n",
    "        return max(candidates, key=lambda x: trigram_freqdist[x])[2]\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 Code Start here\n",
    "\n",
    "Below is the required preprossing for task 2\n",
    "and Setting of postive and negative reviews distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_word_freq = FreqDist()\n",
    "negative_word_freq = FreqDist()\n",
    "\n",
    "reviews_with_sentiment = []\n",
    "with open(\"IMDB Dataset.csv\", encoding='utf-8') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        if row:\n",
    "            review, sentiment = row[0], row[1]\n",
    "            reviews_with_sentiment.append((review, sentiment))\n",
    "\n",
    "for review, sentiment in reviews_with_sentiment:\n",
    "    tokens = word_tokenize(review)\n",
    "    lowercase_tokens = [token.lower() for token in tokens]\n",
    "    cleaned_tokens = [word for word in lowercase_tokens if word.isalpha()]\n",
    "\n",
    "    if sentiment == 'positive':\n",
    "        positive_word_freq.update(cleaned_tokens)\n",
    "    else:\n",
    "        negative_word_freq.update(cleaned_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for generating review for the us.\n",
    "\n",
    "We have to give it some start word and some the length of which we want our review size to be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_review(start_word, max_length=5):\n",
    "    review = [start_word]\n",
    "    \n",
    "    for _ in range(max_length - 1):\n",
    "        if len(review) >= 2:\n",
    "            next_word = predict_trigram((review[-2], review[-1]))\n",
    "            if next_word:\n",
    "                review.append(next_word)\n",
    "            else:\n",
    "                next_word = predict_bigram(review[-1])\n",
    "                if next_word:\n",
    "                    review.append(next_word)\n",
    "                else:\n",
    "                    break\n",
    "        elif len(review) == 1:\n",
    "            next_word = predict_bigram(review[-1])\n",
    "            if next_word:\n",
    "                review.append(next_word)\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    return ' '.join(review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for classifying review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(review):\n",
    "    tokens = word_tokenize(review)\n",
    "    cleaned_tokens = [word.lower() for word in tokens if word.isalpha()]\n",
    "    \n",
    "    positive_prob = 0\n",
    "    negative_prob = 0\n",
    "    \n",
    "    total_positive_words = sum(positive_word_freq.values())\n",
    "    total_negative_words = sum(negative_word_freq.values())\n",
    "    \n",
    "    vocab_size = len(set(positive_word_freq.keys()).union(set(negative_word_freq.keys())))\n",
    "    \n",
    "    # Calculate the log probabilities of each class\n",
    "    for token in cleaned_tokens:\n",
    "        positive_prob += (positive_word_freq[token] + 1) / (total_positive_words + vocab_size)\n",
    "        negative_prob += (negative_word_freq[token] + 1) / (total_negative_words + vocab_size)\n",
    "    \n",
    "    if positive_prob > negative_prob:\n",
    "        return \"positive\"\n",
    "    else:\n",
    "        return \"negative\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the review now and classifying it by calling the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Review: action and the film is a very good and the\n",
      "Generated Review Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "sample_review = generate_review('action', max_length=10)\n",
    "print(\"Generated Review:\", sample_review)\n",
    "\n",
    "generated_review_sentiment = classify_review(sample_review)\n",
    "print(\"Generated Review Sentiment:\", generated_review_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
